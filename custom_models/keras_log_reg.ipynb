{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for keras logistic regression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import preprocessing_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocessing_custom.sampleImages(1000, 1000, 1000)\n",
    "\n",
    "#save X and y\n",
    "np.save('X.npy', X)\n",
    "np.save('y.npy', y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression model\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(3, input_dim=3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 985.7599 - accuracy: 0.4387\n",
      "Epoch 2/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 595.4653 - accuracy: 0.5062\n",
      "Epoch 3/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 474.1818 - accuracy: 0.5293\n",
      "Epoch 4/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 334.1909 - accuracy: 0.5809\n",
      "Epoch 5/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 249.5305 - accuracy: 0.6080\n",
      "Epoch 6/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 350.7368 - accuracy: 0.5969\n",
      "Epoch 7/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 308.5770 - accuracy: 0.6276\n",
      "Epoch 8/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 554.8606 - accuracy: 0.5773\n",
      "Epoch 9/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 359.1920 - accuracy: 0.6324\n",
      "Epoch 10/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 376.9597 - accuracy: 0.6627\n",
      "Epoch 11/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 215.4756 - accuracy: 0.7382\n",
      "Epoch 12/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 238.9090 - accuracy: 0.6964\n",
      "Epoch 13/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 263.6414 - accuracy: 0.7098\n",
      "Epoch 14/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 236.3178 - accuracy: 0.7244\n",
      "Epoch 15/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 211.8798 - accuracy: 0.7240\n",
      "Epoch 16/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 90.9517 - accuracy: 0.8258\n",
      "Epoch 17/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 221.0722 - accuracy: 0.7258\n",
      "Epoch 18/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 233.4623 - accuracy: 0.7280\n",
      "Epoch 19/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 111.1853 - accuracy: 0.8098\n",
      "Epoch 20/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 132.6228 - accuracy: 0.7902\n",
      "Epoch 21/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 214.9645 - accuracy: 0.7671\n",
      "\n",
      "accuracy: 53.73%\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(np.array(X_train), \n",
    "          y_train, \n",
    "          epochs=30, \n",
    "          batch_size=20, \n",
    "          verbose=1,\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
