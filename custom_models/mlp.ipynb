{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import load_img\n",
    "from keras.utils import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASET_PATH = '/Users/yurirykhlo/dev/ECE460JFinalPrject/datasets/'\n",
    "DIGITAL_IMAGES_PATH = 'digital/StableDiffusion/'\n",
    "REAL_IMAGES_PATH = 'real-world/'\n",
    "PAINTING_IMAGES_PATH = 'Non-digital Artwork/'\n",
    "\n",
    "SEED = 69420\n",
    "\n",
    "def is_directory(path):\n",
    "    return os.path.isdir(path)\n",
    "\n",
    "def getImageFiles(image_class):\n",
    "    if image_class == 'digital':\n",
    "        files = os.listdir(DATASET_PATH + DIGITAL_IMAGES_PATH)\n",
    "        return [DIGITAL_IMAGES_PATH + file for file in files]\n",
    "    \n",
    "    elif image_class == 'real':\n",
    "        dirs = [dir for dir in os.listdir(DATASET_PATH + REAL_IMAGES_PATH) if is_directory(DATASET_PATH + REAL_IMAGES_PATH + dir)]\n",
    "        real_images_files = np.array([])\n",
    "        for dir in dirs:\n",
    "            images = os.listdir(DATASET_PATH + REAL_IMAGES_PATH + dir)\n",
    "            images = [REAL_IMAGES_PATH + dir + '/' + image for image in images]\n",
    "            real_images_files = np.append(real_images_files, images)\n",
    "        return real_images_files\n",
    "    \n",
    "    elif image_class == 'painting':\n",
    "        painting_images_dirs = [dir for dir in os.listdir(DATASET_PATH + PAINTING_IMAGES_PATH) if is_directory(DATASET_PATH + PAINTING_IMAGES_PATH + dir)]\n",
    "        painting_images_files = np.array([])\n",
    "        for dir in painting_images_dirs:\n",
    "            images = os.listdir(DATASET_PATH + PAINTING_IMAGES_PATH + dir)\n",
    "            images = [PAINTING_IMAGES_PATH + dir + '/' + image for image in images if not image == '.DS_Store']\n",
    "            painting_images_files = np.append(painting_images_files, images)\n",
    "        return painting_images_files\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('image_class must be one of digital, real, or painting')\n",
    "\n",
    "def sampleImages(digital_image_samples, real_world_samples, artwork_samples, dimension=(224,224)):\n",
    "    digital_images_files = getImageFiles('digital')\n",
    "    real_world_images_files = getImageFiles('real')\n",
    "    artwork_images_files = getImageFiles('painting')\n",
    "\n",
    "    random.seed(SEED)\n",
    "\n",
    "    digital_sampled_images = random.sample(list(digital_images_files), digital_image_samples)\n",
    "    real_sampled_images = random.sample(list(real_world_images_files), real_world_samples)\n",
    "    artwork_sampled_images = random.sample(list(artwork_images_files), artwork_samples)\n",
    "\n",
    "    # concatenate all samples\n",
    "    sampled_images = np.concatenate((digital_sampled_images, real_sampled_images, artwork_sampled_images), axis=0)\n",
    "\n",
    "    images = np.empty((0, dimension[0], dimension[1], 3))\n",
    "    for image in sampled_images:\n",
    "        img = load_img(DATASET_PATH + image, target_size=dimension)\n",
    "        data = img_to_array(img)\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        images = np.append(images, data, axis=0)\n",
    "\n",
    "    # create labels\n",
    "    digital_labels = [0 for i in range(digital_image_samples)]\n",
    "    real_labels = [1 for i in range(real_world_samples)]\n",
    "    artwork_labels = [2 for i in range(artwork_samples)]\n",
    "    labels = np.concatenate((digital_labels, real_labels, artwork_labels), axis=0)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# X, Y = sampleImages(1000, 1000,1000)\n",
    "# Save X and Y using pickle\n",
    "# with open('X_224.pickle', 'wb') as file_X:\n",
    "#     pickle.dump(X, file_X)\n",
    "\n",
    "# with open('Y_224.pickle', 'wb') as file_Y:\n",
    "#     pickle.dump(Y, file_Y)\n",
    "\n",
    "    # Load X and Y using pickle\n",
    "with open('X_224.pickle', 'rb') as file_X:\n",
    "    X = pickle.load(file_X)\n",
    "\n",
    "with open('Y_224.pickle', 'rb') as file_Y:\n",
    "    Y = pickle.load(file_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def preprocess_image(image_path, target_size=(128, 128)):\n",
    "#     img = load_img(image_path, target_size=target_size)\n",
    "#     img_array = img_to_array(img) / 255.0\n",
    "#     return img_array.flatten()\n",
    "\n",
    "# def train_model(X, Y):\n",
    "#     # Split the dataset into train and test sets\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "#     # Reshape the input data to be 2D\n",
    "#     x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "#     # Create and train the MLP model\n",
    "#     mlp = MLPClassifier(hidden_layer_sizes=(512, 256, 128), activation='relu', solver='adam', max_iter=100, random_state=SEED, verbose=True)\n",
    "#     mlp.fit(x_train, y_train)\n",
    "\n",
    "#     # Predict on the test set\n",
    "#     y_pred = mlp.predict(x_test)\n",
    "\n",
    "#     # Calculate the accuracy\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "#     return mlp\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# mlp_model = train_model(X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with batch_size=32, learning_rate=0.001, dropout_rate=0.5\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 12:15:53.248710: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 11s 165ms/step - loss: 9930.2080 - accuracy: 0.3270 - val_loss: 1083.3889 - val_accuracy: 0.3450\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 9s 141ms/step - loss: 2132.5210 - accuracy: 0.3825 - val_loss: 195.1116 - val_accuracy: 0.2700\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 9s 139ms/step - loss: 235.5647 - accuracy: 0.3385 - val_loss: 2.0097 - val_accuracy: 0.3350\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 9s 140ms/step - loss: 8.5326 - accuracy: 0.3330 - val_loss: 2.1140 - val_accuracy: 0.3360\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 9s 140ms/step - loss: 3.2001 - accuracy: 0.3340 - val_loss: 1.6074 - val_accuracy: 0.3380\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 9s 140ms/step - loss: 3.7925 - accuracy: 0.3335 - val_loss: 1.4866 - val_accuracy: 0.3380\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 9s 140ms/step - loss: 3.4029 - accuracy: 0.3345 - val_loss: 1.3265 - val_accuracy: 0.3360\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 9s 146ms/step - loss: 1.5155 - accuracy: 0.3195 - val_loss: 1.3187 - val_accuracy: 0.3370\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 9s 142ms/step - loss: 1.1540 - accuracy: 0.3325 - val_loss: 1.3124 - val_accuracy: 0.3380\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 9s 147ms/step - loss: 2.2704 - accuracy: 0.3305 - val_loss: 1.3054 - val_accuracy: 0.3380\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 1.3054 - accuracy: 0.3380\n",
      "Fold accuracy: 33.80%\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 11s 171ms/step - loss: 9695.1562 - accuracy: 0.3500 - val_loss: 2860.6797 - val_accuracy: 0.3330\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 11s 165ms/step - loss: 1711.9879 - accuracy: 0.3505 - val_loss: 169.4797 - val_accuracy: 0.4380\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 10s 159ms/step - loss: 136.0456 - accuracy: 0.3320 - val_loss: 1.7834 - val_accuracy: 0.3320\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 10s 158ms/step - loss: 4.2741 - accuracy: 0.3325 - val_loss: 1.4284 - val_accuracy: 0.3330\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 10s 158ms/step - loss: 2.2662 - accuracy: 0.3340 - val_loss: 1.4440 - val_accuracy: 0.3320\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 10s 158ms/step - loss: 2.9676 - accuracy: 0.3345 - val_loss: 1.3203 - val_accuracy: 0.3320\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 10s 158ms/step - loss: 3.4821 - accuracy: 0.3340 - val_loss: 1.3879 - val_accuracy: 0.3320\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 10s 158ms/step - loss: 2.8526 - accuracy: 0.3320 - val_loss: 1.2246 - val_accuracy: 0.3330\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 10s 158ms/step - loss: 2.0731 - accuracy: 0.3275 - val_loss: 1.1000 - val_accuracy: 0.3360\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 10s 161ms/step - loss: 2.1834 - accuracy: 0.3255 - val_loss: 1.0990 - val_accuracy: 0.3360\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 1.0990 - accuracy: 0.3360\n",
      "Fold accuracy: 33.60%\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 12s 180ms/step - loss: 9292.5137 - accuracy: 0.3515 - val_loss: 868.5399 - val_accuracy: 0.3750\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 10s 162ms/step - loss: 1972.8540 - accuracy: 0.3795 - val_loss: 357.9802 - val_accuracy: 0.3740\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 10s 160ms/step - loss: 237.2566 - accuracy: 0.3375 - val_loss: 2.1994 - val_accuracy: 0.3300\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 10s 161ms/step - loss: 4.0713 - accuracy: 0.3335 - val_loss: 2.0186 - val_accuracy: 0.3330\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 10s 160ms/step - loss: 3.7549 - accuracy: 0.3320 - val_loss: 1.9615 - val_accuracy: 0.3330\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 3.7065 - accuracy: 0.3340 - val_loss: 1.8578 - val_accuracy: 0.3330\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 10s 161ms/step - loss: 1.5790 - accuracy: 0.3290 - val_loss: 1.6960 - val_accuracy: 0.3360\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 10s 161ms/step - loss: 1.1479 - accuracy: 0.3345 - val_loss: 1.6789 - val_accuracy: 0.3360\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 10s 160ms/step - loss: 4.8126 - accuracy: 0.3335 - val_loss: 1.6576 - val_accuracy: 0.3340\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 10s 161ms/step - loss: 1.3817 - accuracy: 0.3315 - val_loss: 1.6315 - val_accuracy: 0.3340\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 1.6315 - accuracy: 0.3340\n",
      "Fold accuracy: 33.40%\n",
      "\n",
      "Best hyperparameters:\n",
      "Batch size: 32\n",
      "Learning rate: 0.001\n",
      "Dropout rate: 0.5\n",
      "Best accuracy: 33.60%\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "def create_model(learning_rate, dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(224, 224, 3)))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(X, Y, batch_size, learning_rate, dropout_rate, n_folds=3):\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "    fold_accuracy = []\n",
    "\n",
    "    Y = to_categorical(Y, num_classes=3)\n",
    "\n",
    "    for train, val in kfold.split(X, np.argmax(Y, axis=1)):\n",
    "        x_train = X[train]\n",
    "        y_train = Y[train]\n",
    "        x_val = X[val]\n",
    "        y_val = Y[val]\n",
    "\n",
    "        model = create_model(learning_rate, dropout_rate)\n",
    "\n",
    "        hist = model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=10, verbose=1, validation_data=(x_val, y_val), shuffle=True, workers=1, use_multiprocessing=True)\n",
    "\n",
    "        scores = model.evaluate(x_val, y_val, verbose=1)\n",
    "        fold_accuracy.append(scores[1] * 100)\n",
    "        print(f\"Fold accuracy: {scores[1]*100:.2f}%\")\n",
    "\n",
    "    return np.mean(fold_accuracy), model\n",
    "\n",
    "\n",
    "batch_sizes = [16, 32]\n",
    "learning_rates = [0.001, 0.0005]\n",
    "dropout_rates = [0.5, 0.6]\n",
    "\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_hyperparams = {\n",
    "    'batch_size': batch_sizes[0],\n",
    "    'learning_rate': learning_rates[0],\n",
    "    'dropout_rate': dropout_rates[0],\n",
    "}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for learning_rate in learning_rates:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            print(f\"\\nTraining with batch_size={batch_size}, learning_rate={learning_rate}, dropout_rate={dropout_rate}\")\n",
    "            accuracy, model = train_model(X, Y, batch_size, learning_rate, dropout_rate)\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_model = model\n",
    "                best_accuracy = accuracy\n",
    "                best_hyperparams['batch_size'] = batch_size\n",
    "                best_hyperparams['learning_rate'] = learning_rate\n",
    "                best_hyperparams['dropout_rate'] = dropout_rate\n",
    "\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(f\"Batch size: {best_hyperparams['batch_size']}\")\n",
    "print(f\"Learning rate: {best_hyperparams['learning_rate']}\")\n",
    "print(f\"Dropout rate: {best_hyperparams['dropout_rate']}\")\n",
    "print(f\"Best accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "best_model.save('mlp_fully_trained.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
