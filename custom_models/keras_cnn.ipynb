{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import preprocessing_custom\n",
    "\n",
    "SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample 500 images from digital, non-digital artwork, and real_world\n",
    "\n",
    "\n",
    "# def sample_images():\n",
    "#     # sample 500 images from digital, non-digital artwork, and real_world\n",
    "#     non_digital_artwork = os.listdir('./datasets/Non-digital Artwork')\n",
    "#     real_world = os.listdir('./datasets/real-world')\n",
    "    \n",
    "#     # digital but only diffusion\n",
    "#     digitals = random.sample(os.listdir('./datasets/digital/StableDiffusion/'), math.ceil(SIZE/3))\n",
    "\n",
    "#     # non-digitals\n",
    "#     non_digitals = []\n",
    "#     for folder in non_digital_artwork:\n",
    "#         list = os.listdir('./datasets/Non-digital Artwork/' + folder)\n",
    "#         for elem in range(len(list)):\n",
    "#             list[elem] = './datasets/Non-digital Artwork/' + folder + '/' + str(list[elem])\n",
    "#         random.shuffle(list)\n",
    "#         non_digitals = non_digitals + list[:math.ceil(math.ceil(SIZE/3)/len(non_digital_artwork))]\n",
    "\n",
    "#     # real_world\n",
    "#     real_worlds = []\n",
    "#     for folder in real_world:\n",
    "#         list = os.listdir('./datasets/real-world/' + folder)\n",
    "#         for elem in range(len(list)):\n",
    "#             list[elem] = './datasets/real-world/' + folder + '/' + str(list[elem])\n",
    "#         random.shuffle(list)\n",
    "#         real_worlds = real_worlds + list[:math.ceil(math.ceil(SIZE/3)/len(real_world))]\n",
    "\n",
    "#     # put images in dataframe\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for image in digitals:\n",
    "#         images.append('./datasets/digital/StableDiffusion/' + image)\n",
    "#         labels.append('Digital')\n",
    "#     print(len(images))\n",
    "#     for image in non_digitals:\n",
    "#         images.append(image)\n",
    "#         labels.append('Non-digital Artwork')\n",
    "#     print(len(images))\n",
    "#     for image in real_worlds:\n",
    "#         images.append(image)\n",
    "#         labels.append('Real World')\n",
    "#     print(len(images))\n",
    "    \n",
    "#     data = {'image': images, 'label': labels}\n",
    "#     df = pd.DataFrame(data)\n",
    "#     data = df.sample(frac=1)[:SIZE]\n",
    "#     print(len(data))\n",
    "#     return data\n",
    "\n",
    "# full_dataset = sample_images()\n",
    "# print(full_dataset.head())\n",
    "\n",
    "# X, y = preprocessing_custom.sampleImages(1000, 1000, 1000)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "# load X and y from keras_log_reg to save time\n",
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), input_shape=(128, 128, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# create tensorboard\n",
    "NAME = \"Original_CNN\"\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding y train...\n",
      "Encoding y test...\n",
      "Rescaling train images...\n",
      "Rescaling test images...\n"
     ]
    }
   ],
   "source": [
    "# # rescale images\n",
    "# print(\"Encoding y train...\")\n",
    "# y_train_encoded = []\n",
    "# for label in y_train:\n",
    "#     if label == 'Digital':\n",
    "#         y_train_encoded.append([1, 0, 0])\n",
    "#     elif label == 'Non-digital Artwork':\n",
    "#         y_train_encoded.append([0, 1, 0])\n",
    "#     else:\n",
    "#         y_train_encoded.append([0, 0, 1])\n",
    "# y_train_encoded = np.asarray(y_train_encoded)\n",
    "\n",
    "# print(\"Encoding y test...\")\n",
    "# y_test_encoded = []\n",
    "# for label in y_test:\n",
    "#     if label == 'Digital':\n",
    "#         y_test_encoded.append([1, 0, 0])\n",
    "#     elif label == 'Non-digital Artwork':\n",
    "#         y_test_encoded.append([0, 1, 0])\n",
    "#     else:\n",
    "#         y_test_encoded.append([0, 0, 1])\n",
    "# y_test_encoded = np.asarray(y_test_encoded)\n",
    "\n",
    "# print(\"Rescaling train images...\")\n",
    "# rescaled_x_train = np.empty((0, 224, 224, 3))\n",
    "# for image in X_train:\n",
    "#     img = tf.keras.preprocessing.image.load_img(image, target_size=(224, 224))\n",
    "#     img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "#     img = np.expand_dims(img, axis = 0)\n",
    "#     rescaled_x_train = np.append(rescaled_x_train, img, axis = 0)\n",
    "\n",
    "# print(\"Rescaling test images...\")\n",
    "# rescaled_x_test = np.empty((0, 224, 224, 3))\n",
    "# for image in X_test:\n",
    "#     img = tf.keras.preprocessing.image.load_img(image, target_size=(224, 224))\n",
    "#     img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "#     img = np.expand_dims(img, axis = 0)\n",
    "#     rescaled_x_test = np.append(rescaled_x_test, img, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Epoch 1/30\n",
      "Epoch 2/30\n",
      "Epoch 3/30\n",
      "Epoch 4/30\n",
      "Epoch 5/30\n",
      "Epoch 6/30\n",
      "Epoch 7/30\n",
      "Epoch 8/30\n",
      "Epoch 9/30\n",
      "Epoch 10/30\n",
      "Epoch 11/30\n",
      "Epoch 12/30\n",
      "Epoch 13/30\n",
      "Epoch 14/30\n",
      "Epoch 15/30\n",
      "Epoch 16/30\n",
      "Epoch 17/30\n",
      "Epoch 18/30\n",
      "Epoch 19/30\n",
      "Epoch 20/30\n",
      "Epoch 21/30\n",
      "Epoch 22/30\n",
      "Epoch 23/30\n",
      "Epoch 24/30\n",
      "Epoch 25/30\n",
      "Epoch 26/30\n",
      "Epoch 27/30\n",
      "Epoch 28/30\n",
      "Epoch 29/30\n",
      "Epoch 30/30\n",
      "Evaluating model...\n",
      "24/24 [==============================] - 10s 394ms/step - loss: 6.8773 - accuracy: 0.5320\n",
      "Test accuracy: 0.5320000052452087\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Fitting model...\")\n",
    "model.fit(np.array(X_train), \n",
    "          y_train, \n",
    "          epochs=30,\n",
    "          verbose=5, \n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# save model\n",
    "# model.save('keras_cnn.model')\n",
    "\n",
    "# evaluate model\n",
    "print(\"Evaluating model...\")\n",
    "test_loss, test_acc = model.evaluate(np.array(X_test), np.array(y_test))\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
